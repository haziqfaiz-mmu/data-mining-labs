{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"mmu_logo.png\" style=\"height: 80px;\" align=left> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Objectives\n",
    "\n",
    "Towards the end of this lesson, you should be able to:\n",
    "- differentiate classification and regression tree\n",
    "- program in CART using ``DecisionTreeClassifier``, ``DecisionTreeRegressor``\n",
    "- program a SVM model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the relevant libraries\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing # label encoding\n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "from sklearn.tree import DecisionTreeRegressor  \n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split functionn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "import sklearn.metrics as sm\n",
    "\n",
    "from IPython.display import Image  \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing a Decision Tree Classifier\n",
    "\n",
    "you need to load ``from sklearn.tree import DecisionTreeClassifier``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load diabetes.csv dataset\n",
    "\n",
    "pima = pd.read_csv(\"diabetes.csv\")\n",
    "pima.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data types\n",
    "\n",
    "pima.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the class variable must be categorical data. Take note of the change in data type for Outcome\n",
    "\n",
    "pima.Outcome = pima['Outcome'].apply(str)\n",
    "\n",
    "pima.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset in features and target variable*\n",
    "\n",
    "feature_cols = ['Pregnancies', 'Insulin', 'BMI', 'Age','Glucose','BloodPressure','DiabetesPedigreeFunction'] \n",
    "X = pima[feature_cols] # Features\n",
    "y = pima.Outcome # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "# 70-30 split and set random_state=1\n",
    "# your codes here...\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object and list all the default parameters\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Decision Tree Classifer using default parameters\n",
    "# your codes here...\n",
    "\n",
    "#Predict the response for the test dataset\n",
    "# your codes here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn=X.columns\n",
    "cn=['0','1']\n",
    "fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (4,4), dpi=300)\n",
    "tree.plot_tree(clf,\n",
    "               feature_names = fn, \n",
    "               class_names=cn,\n",
    "               filled = True);\n",
    "fig.savefig('imagename.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** the ``value`` represents the value for class 0 and 1, respectively\n",
    "\n",
    "In the decision tree chart, each internal node has a decision rule that splits the data. Gini referred as Gini ratio, which measures the impurity of the node. You can say a node is pure when all of its records belong to the same class, such nodes known as the leaf node.\n",
    "Here, the resultant tree is unpruned. This unpruned tree is unexplainable and not easy to understand. In the next section, let's optimize it by pruning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying the Decision Tree Parameters\n",
    "\n",
    "Try change from ``Gini`` to ``Entropy``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "# your codes here...\n",
    " \n",
    "# Train Decision Tree Classifer*\n",
    "# your codes here...\n",
    "\n",
    "#Predict the response for test dataset*\n",
    "# your codes here...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model accuracy\n",
    "# your codes here...\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the decision-tree\n",
    "\n",
    "fn=X.columns\n",
    "cn=['0','1']\n",
    "fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (4,4), dpi=300)\n",
    "tree.plot_tree(clf,\n",
    "               feature_names = fn, \n",
    "               class_names=cn,\n",
    "               filled = True);\n",
    "fig.savefig('imagename.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is the read the model generated above!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing a Regression Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load petrol_consumption.csv dataset\n",
    "\n",
    "dataset = pd.read_csv('petrol_consumption.csv')  \n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset X and y.\n",
    "\n",
    "X = dataset.drop('Petrol_Consumption', axis=1)  \n",
    "y = dataset['Petrol_Consumption']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split by 80-20, random_state=20\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model using default hyperparameters\n",
    "# your codes here...\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your codes here...\n",
    "\n",
    "df=pd.DataFrame({'Actual':y_test, 'Predicted':y_pred})  \n",
    "df  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If MAE is less than 10 percent of the mean of all the values in the 'Petrol_Consumption' column. This means that our algorithm did a fine prediction job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your codes here...\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn=X.columns\n",
    "fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (4,4), dpi=300)\n",
    "tree.plot_tree(regressor,\n",
    "               feature_names = fn,  \n",
    "               filled = True);\n",
    "fig.savefig('imagename.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the max_depth to regressor --> regressor = DecisionTreeRegressor(max_depth=3). See the resulting tree! Check the MAE with this new model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Support Vector Machine (SVM)\n",
    "SVM is particularly powerful and flexible class of supervised algorithms for both classification and regression. In this section, we will develop the intuition behind support vector machines and their use in classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Iris dataset\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2] \n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the data - only Sepal length and sepal width\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "h = (x_max / x_min)/100\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.xlim(xx.min(), xx.max()) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSVC(title):\n",
    "    # create a mesh to plot in\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    h = (x_max / x_min)/100\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\n",
    "\n",
    "    plt.subplot(1, 1, 1)\n",
    "    Z = svc.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.8)\n",
    "\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired)\n",
    "    plt.xlabel('Sepal length')\n",
    "    plt.ylabel('Sepal width')\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel\n",
    "kernel parameters selects the type of hyperplane used to separate the data. Using ‘linear’ will use a linear hyperplane (a line in the case of 2D data). ‘rbf’ and ‘poly’ uses a non linear hyper-plane\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = ['linear', 'rbf', 'poly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kernel in kernels:\n",
    "    svc = svm.SVC(kernel=kernel, gamma='auto').fit(X, y)\n",
    "    plotSVC('kernel=' + str(kernel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gamma\n",
    "gamma is a parameter for non linear hyperplanes. The higher the gamma value it tries to exactly fit the training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gammas = [0.1, 1, 10, 100]\n",
    "\n",
    "for gamma in gammas:\n",
    "    svc = svm.SVC(kernel='rbf', gamma=gamma).fit(X, y)\n",
    "    plotSVC('gamma=' + str(gamma))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C\n",
    "C is the penalty parameter of the error term. It controls the trade off between smooth decision boundary and classifying the training points correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = [0.1, 1, 10, 100, 1000]\n",
    "\n",
    "for c in cs:\n",
    "    svc = svm.SVC(kernel='rbf', C=c, gamma ='auto').fit(X, y)\n",
    "    plotSVC('C=' + str(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# degree\n",
    "\n",
    "degree is a parameter used when kernel is set to ‘poly’. It’s basically the degree of the polynomial used to find the hyperplane to split the data.\n",
    "\n",
    "Using degree=1 is the same as using a ‘linear’ kernel. Also, increasing this parameters leads to higher training times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "start = timer()\n",
    "\n",
    "degrees = [1,3,5,7]\n",
    "\n",
    "for degree in degrees:\n",
    "    svc = svm.SVC(kernel='poly', degree=degree, gamma='auto').fit(X, y)\n",
    "    plotSVC('degree=' + str(degree))\n",
    "    \n",
    "end = timer()\n",
    "\n",
    "print('time spent =', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing a SVM Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "#Load dataset\n",
    "cancer = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Features: \", cancer.feature_names)\n",
    "\n",
    "# print the label type of cancer('malignant' 'benign')\n",
    "print(\"Labels: \", cancer.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore it for a bit more. You can also check the shape of the dataset using shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cancer.data[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the cancer labels (0:malignant, 1:benign)\n",
    "print(cancer.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.3,random_state=109) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import svm model\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "# your codes here...\n",
    "\n",
    "#Train the model using the training sets\n",
    "# your codes here...\n",
    "\n",
    "#Predict the response for test dataset\n",
    "# your codes here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Accuracy: how often is the classifier correct?\n",
    "\n",
    "# your codes here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your codes here...\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "# your codes here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your tasks 1:\n",
    "\n",
    "1. Load the diabetes dataset\n",
    "2. Perform classification on the dataset (select 100 rows, test size =0.2) and check the accuracy using:\n",
    "    - kernel = rbf , linear , poly with degree=2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "df = pd.read_csv('diabetes_data.csv')\n",
    "\n",
    "# your codes here...\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your tasks 2:\n",
    "\n",
    "1. Load the banknote dataset\n",
    "2. Perform classification on the dataset and check the accuracy using:\n",
    "    - kernel = rbf , linear , poly with degree=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "df = pd.read_csv('banknote.csv') \n",
    "X = df.drop(\"Class\", axis=1)\n",
    "y = df.Class\n",
    "\n",
    "# your codes here...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
