{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"mmu_logo.png\" style=\"height: 80px;\" align=left>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4: Learning Objectives\n",
    "\n",
    "Towards the end of this lesson, you should be able to:\n",
    "- write Python codes for association rule mining\n",
    "- experimenting with laundry dataset and linear regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from apyori import apriori\n",
    "import seaborn as sns \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Association Rule Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load store_data.csv dataset\n",
    "\n",
    "store_data = pd.read_csv('store_data.csv', header=None)\n",
    "store_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "The Apriori library we are going to use requires our dataset to be in the form of a list of lists, where the whole dataset is a big list and each transaction in the dataset is an inner list within the outer big list. Currently we have data in the form of a pandas dataframe. To convert our pandas dataframe into a list of lists, execute the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the original dataset into ARM friendly format\n",
    "\n",
    "records = []\n",
    "\n",
    "# your codes here...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Apriori Algorithm\n",
    "\n",
    "You must set the parameters in the apriori algorithm. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run apriori function\n",
    "\n",
    "# your codes here...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(association_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(association_results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output in better presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt =0\n",
    "\n",
    "for item in association_results:\n",
    "    cnt += 1\n",
    "    # first index of the inner list\n",
    "    # Contains base item and add item\n",
    "    pair = item[0] \n",
    "    items = [x for x in pair]\n",
    "    print(\"(Rule \" + str(cnt) + \") \" + items[0] + \" -> \" + items[1])\n",
    "\n",
    "    #second index of the inner list\n",
    "    print(\"Support: \" + str(round(item[1],3)))\n",
    "\n",
    "    #third index of the list located at 0th\n",
    "    #of the third index of the inner list\n",
    "\n",
    "    print(\"Confidence: \" + str(round(item[2][0][2],4)))\n",
    "    print(\"Lift: \" + str(round(item[2][0][3],4)))\n",
    "    print(\"=====================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame()\n",
    "for i in range(4):\n",
    "    filename = './data/file' + str(i+1) + \".xlsx\"\n",
    "    df = pd.read_excel(filename, sheet_name='Reading', skiprows = 2, usecols = 'G:AB') \n",
    "    df.drop(df.index[31:], inplace=True)\n",
    "    df_all = df_all.append(df) \n",
    "df_all = df_all.fillna(0)\n",
    "df_all = df_all/56*5 # this is just a data transformation to Ringgit Malaysia\n",
    "df_all = df_all.round(2)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the dataset format\n",
    "\n",
    "df_all_melt = df_all.melt()\n",
    "df_all_melt.columns = ['Item', 'Sales']\n",
    "a=df_all_melt.loc[df_all_melt['Item']=='Detergent 1','Sales']\n",
    "df_all_melt['Sales'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(11,6)})\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "a = sns.stripplot(x=\"Item\", y=\"Sales\", data=df_all_melt)\n",
    "a.set_xticklabels(a.get_xticklabels(), rotation=90)\n",
    "a.set_title('Items and Sales')\n",
    "a.set_ylabel('Sales')\n",
    "a.set_xlabel('Items')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot swarmplot\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11, 6)})\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "# your codes here...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot pairplot\n",
    "\n",
    "df_w123 = df_all[['W1','W2','W3']].reset_index()\n",
    "\n",
    "# your codes here...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot heatmap to show the correlation\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11,6)})\n",
    "correlation_matrix = df_all.iloc[:,:].corr().round(1)\n",
    "\n",
    "# your codes here...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grouping for Item-Sales\n",
    "\n",
    "df_itemSales = df_all_melt.groupby([\"Item\"]).sum() \n",
    "df_itemSales.reset_index(inplace=True)\n",
    "df_itemSales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Item-Sales barchart\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11,6)})\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "b = sns.barplot(x=\"Item\", y=\"Sales\",  data=df_itemSales)\n",
    "b.set_xticklabels(b.get_xticklabels(), rotation=90)\n",
    "b.set_title('Item Sales')\n",
    "b.set_ylabel('Sales')\n",
    "b.set_xlabel('Items')\n",
    "b.set(ylim=(0, 10000))\n",
    "\n",
    "for p in b.patches:\n",
    "    \tb.annotate(\"%.0f\" % p.get_height(), (p.get_x() + \n",
    "\tp.get_width() / 2., p.get_height()), \n",
    "    \tha='center', va='center', rotation=90, \n",
    "\txytext=(0, 18), textcoords='offset points')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the daily sales\n",
    "\n",
    "df_dailySales = df_all.groupby(df_all.index).sum() \n",
    "df_dailySales.reset_index(drop=True, inplace=True) \n",
    "df_dailySales = df_dailySales.sum(axis=1).to_frame() \n",
    "df_dailySales.columns = ['Sales'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot daily sales\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11, 6)})\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "b = sns.barplot(x=df_dailySales.index, y=\"Sales\",  data=df_dailySales)\n",
    "b.set_xticklabels(b.get_xticklabels(), rotation=0)\n",
    "b.set_title('Daily Sales')\n",
    "b.set_ylabel('Sales')\n",
    "b.set_xlabel('Day')\n",
    "\n",
    "b.set(ylim=(0, 5000))\n",
    "\n",
    "for p in b.patches:\n",
    "    \tb.annotate(\"%.0f\" % p.get_height(), (p.get_x() + \n",
    "\tp.get_width() / 2., p.get_height()), \n",
    "    \tha='center', va='center', rotation=90, \n",
    "\txytext=(0, 18), textcoords='offset points')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the distribution plot for VM_Sum\n",
    "\n",
    "df_all['VM_Sum'] = df_all.loc[:, 'Detergent 1':'Bag 2'].sum(axis=1)\n",
    "sns.distplot(df_all['VM_Sum'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Scatterplot for 5 washers\n",
    "\n",
    "features = ['W1', 'W2', 'W3', 'W4', 'W5', 'W6']\n",
    "target = df_all['VM_Sum']\n",
    "\n",
    "for i, col in enumerate(features):\n",
    "    plt.subplot(1, len(features) , i+1)\n",
    "    x = df_all[col]\n",
    "    y = target\n",
    "    sns.scatterplot(x,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR using statemodels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset for Linear Regression for W3 agains VM_Sum\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X = df_all[['W3']]\n",
    "Y = df_all[['VM_Sum']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using OLS\n",
    "\n",
    "# your codes here...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X['W3'],Y)\n",
    "plt.scatter(X['W3'],predictions, color='red')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the model summary\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(Y, X).fit()\n",
    "predictions = model.predict(X)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X['W3'],Y)\n",
    "plt.scatter(X['W3'],predictions, color='red')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_all.loc[:,'W3'] \n",
    "Y = df_all.loc[:,'VM_Sum'] \n",
    "\n",
    "plt.plot(X,Y, linestyle='',marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_all.loc[:,['W3']] \n",
    "Y = df_all.loc[:,'VM_Sum'] \n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.20, random_state = 5)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression model construction\n",
    "\n",
    "# your codes here...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the coefficient\n",
    "\n",
    "lm.coef_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the intercept\n",
    "\n",
    "lm.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform prediction on X_test\n",
    "\n",
    "# your codes here...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a table to compare VM_Sum and PredictedSum\n",
    "\n",
    "df_tmp = df_all.loc[:,['W3','VM_Sum']]\n",
    "df_new = pd.concat([df_tmp.reset_index(drop=True), Y_test_pred], axis=1) \n",
    "df_new.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a scatterplot to compare W3 and PredictedSum and VM_Sum\n",
    "\n",
    "plt.plot( 'W3', 'PredictedSum', data=df_new, linestyle='', marker='o')  \n",
    "plt.plot( 'W3', 'VM_Sum', data=df_new, linestyle='', marker='+') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot X_test agains Y_test and Y_test_pred\n",
    "\n",
    "X_test = X_test.loc[:,'W3']\n",
    "Y_test_pred = Y_test_pred.squeeze()\n",
    "\n",
    "plt.plot(X_test, Y_test, 'o')\n",
    "plt.plot(X_test, Y_test_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.coef_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model to predict Y_test value when X_test = 60\n",
    "\n",
    "# your codes here...\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
