{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"mmu_logo.png\" style=\"height: 80px;\" align=left>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Objectives\n",
    "\n",
    "Towards the end of this lesson, you should be able to:\n",
    "- creating a dataframe using dictionary\n",
    "- using Pandas to manipulate structured dataset \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install pandas\n",
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series\n",
    "Series form the basis of Pandas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Series\n",
    "Series can be initialized from Python objects like lists or tuples. If only values are given, Pandas generates default indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits = ['apple', 'banana', 'durian']\n",
    "pd.Series(fruits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [1, 2, 3]\n",
    "pd.Series(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series can be mixed type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mixed series\n",
    "import pandas as pd\n",
    "mixed = [1, 2, \"Three\"]\n",
    "print(pd.Series(mixed))\n",
    "print()\n",
    "print(type(mixed[0]))\n",
    "print(type(mixed[1]))\n",
    "print(type(mixed[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series also support missing values via the `None` type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a pandas series with None\n",
    "#observe the dtype\n",
    "\n",
    "fruits = ['apple', 'banana', 'durian']\n",
    "print(pd.Series(fruits))\n",
    "print(\"\")\n",
    "print(type(fruits[0]))\n",
    "print(type(fruits[1]))\n",
    "print(type(fruits[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the None keyword in list --> NaN in series\n",
    "\n",
    "import numpy as np\n",
    "numbers = [1, 2, None]\n",
    "print(pd.Series(numbers))\n",
    "print(\"\")\n",
    "print(type(numbers[0]))\n",
    "print(type(numbers[1]))\n",
    "print(type(numbers[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define custom keys during initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to be careful with index. Index can be numbers.\n",
    "\n",
    "fruits = pd.Series(\n",
    "    data=[\"apple\", \"banana\", \"pineapple\", \"durian\"], \n",
    "    index=[\"a\", \"b\", \"c\", \"d\"])\n",
    "print(fruits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to be careful with index. Index can be characters.\n",
    "\n",
    "fruits = pd.Series(\n",
    "    data=[\"apple\", \"banana\", \"pineapple\", \"durian\"], \n",
    "    index=[\"a\", \"b\", \"c\", \"d\"])\n",
    "print(fruits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, Series can also be initialized with dictionaries. Indices are then generated from the dictionary keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our own dictionary\n",
    "\n",
    "dict = {\n",
    "    'australia': 'apple',\n",
    "    'malaysia': 'durian',\n",
    "    'thailand': 'coconut',\n",
    "    'philipines': 'mango'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a pandas series from dictionary\n",
    "\n",
    "country = pd.Series(dict)\n",
    "print(country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can list values and indices of series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(country.index)\n",
    "print(country.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Elements - IMPORTANT\n",
    "As a result of iterative development of the Pandas library, there are several ways to select elements of a Series. Most of them are considered \"legacy\", however, and the best practice is to use `*.loc[...]` and `*.iloc[...]`. Take care to use the square brackets with `loc` and `iloc`, *not* the regular brackets as you would with functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loc\n",
    "Select elements by their indices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(country.loc['malaysia'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iloc\n",
    "Select elements by their numerical IDs, i.e. the n-th element. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(country.iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the indices were autogenerated then both loc and iloc seem to be identical. This is **NOT** always the case !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_noindex = pd.Series(country.values)\n",
    "print(country_noindex)\n",
    "print(\"\")\n",
    "print(country_noindex.loc[0])\n",
    "print(country_noindex.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, change the position by using **sort_values()** command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure you check the index sequence\n",
    "\n",
    "country_noindex_sorted = country_noindex.sort_values()\n",
    "print(country_noindex_sorted)\n",
    "print(\"\")\n",
    "print(country_noindex_sorted.loc[1])\n",
    "print(country_noindex_sorted.iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to select by index then use `loc`, if you want to select by ID then use `iloc`. Do not use them interchangeably just because they return the same results right now. This will eventually lead to bugs in your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Series\n",
    "Series can be combined by appending one to another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the append command\n",
    "\n",
    "s1 = pd.Series([\"A\", \"B\", \"C\"])\n",
    "s2 = pd.Series([\"D\", \"E\", \"F\"])\n",
    "print(s1)\n",
    "print(\"\")\n",
    "print(s2)\n",
    "print(\"\")\n",
    "\n",
    "s3 = s1.append(s2)\n",
    "print(s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the duplicate indices! Pandas permits this and selecting by `loc` will return **both** entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s3.loc[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using ``iloc`` will only return based on index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s3.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also notice that if your selection of a Series results in a single entry, Pandas automatically converts it to its base type, i.e. a string in this case. If the selection consists of more than 1 entry, however, a Series is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s3.loc[0])\n",
    "print(type(s3.loc[0]))\n",
    "print(\"\")\n",
    "print(s3.iloc[0])\n",
    "print(type(s3.iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrames\n",
    "\n",
    "Multiple series with common indices can form a data frame. A data frame is like a table, with rows and columns (e.g., as in SQL or Excel).\n",
    "\n",
    "|     | Region | Weather |\n",
    "| --- | --- | --- |\n",
    "| India | asia | warm |\n",
    "| Sweden | europe | cold |\n",
    "\n",
    "Each row usually denotes an entry in our data and each column a feature we're interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DataFrames from Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {\n",
    "    'Region':['asia','europe'],\n",
    "    'Weather':['warm', 'cold']\n",
    "    }\n",
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the same `*.index()` and `*.values()` functions as for Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.index)\n",
    "print(df.columns)\n",
    "print(df.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Pretty Print in Jupyter\n",
    "\n",
    "A better way to display the output of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter allows a shortcut for the `display` function. If we execute a Python command or line of code that results in a data frame, Jupyter will assume we want to display it and do so using its built-in function. Note, however, that it will only ever do this with the last relevant line in each cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing and Exporting Data\n",
    "Most often we don't create data within our code but read it from external sources. Pandas has a large collection of importing (and corresponding exporting) functions available.\n",
    "\n",
    "| Data | Reader | Writer |\n",
    "| --- | --- | --- |\n",
    "| CSV | `read_csv` | `to_csv` |\n",
    "| JSON | `read_json` | `to_json` |\n",
    "| HTML | `read_html` | `to_html` |\n",
    "| Local clipboard | `read_clipboard` | `to_clipboard` |\n",
    "| Excel | `read_excel` | `to_excel` |\n",
    "| HDF5 | `read_hdf` | `to_hdf` |\n",
    "| Feather | `read_feather` | `to_feather` |\n",
    "| Parquet | `read_parquet` | `to_parquet` |\n",
    "| Msgpack | `read_msgpack` | `to_msgpack` |\n",
    "| Stata | `read_stata` | `to_stata` |\n",
    "| SAS | `read_sas` |  |\n",
    "| Python Picke Format | `read_pickle` | `to_pickle` |\n",
    "| SQL | `read_sql` | `to_sql` |\n",
    "| Google Big Query | `read_gbq` | `to_gbq` |\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/io.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading CSV\n",
    "We will read a tabular CSV file as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"banking.csv\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the **Shape** of the dataframe. It is represented as (*row*,*column*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all the columns of a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing CSV\n",
    "Writing CSV files is as straightforward as it gets. Notice that these functions are now methods of the specific objects, not of base Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"telemarket2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Data\n",
    "Selecting data from Pandas arrays works just as it did for NumPy arrays, except that `loc` and `iloc` are necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row with index no. 9\n",
    "\n",
    "df.iloc[[9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row with index 4 to 6\n",
    "\n",
    "df.iloc[4:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip 2\n",
    "\n",
    "df.iloc[1:9:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting columns from a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select column = 'disp' only\n",
    "\n",
    "df[[\"age\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 2 columns.\n",
    "\n",
    "df[[\"age\", \"job\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can also use the `*.loc`/`.*iloc` syntax. In this case, we have to include both the row and column indices to select. As with base Python, the color `:` instructs Pandas to select all rows or columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select column = 'disp'\n",
    "\n",
    "df.loc[:, [\"job\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting data for a particular row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.iloc[[4]]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting data for a particular cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[4].loc[\"job\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas applies the operation to each individual entry\n",
    "\n",
    "df[\"age\"] > 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use loc, not iloc, to select based on boolean masks\n",
    "\n",
    "df.loc[df[\"age\"] > 25].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also select specific rows of certain columns with boolean masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select specific columns\n",
    "\n",
    "df.loc[df[\"age\"] > 25, [\"job\",\"housing\",'education']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select specific cell...\n",
    "\n",
    "df.iloc[3, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['age'].sum())\n",
    "print(df['age'].mean())\n",
    "print(df['age'].max())\n",
    "print(df['age'].min())\n",
    "print(df['age'].idxmax())\n",
    "print(df['age'].idxmin())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions can be applied to series or data.frames. In the case of data frames, they are applied to each row or column individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df[['age','duration','pdays']]\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean by column\n",
    "\n",
    "df_1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for each column, which index has the max value\n",
    "\n",
    "df_1.idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can decide whether the aggregation should occur along columns or rows. Note however, that the syntax is confusing. `axis=X` indicates along which dimension the function will \"travel\". For example, `axis=columns` indicates that all columns will be collapsed into the function, and the function will be applied to individual rows. Likewise, `axis=rows` means that the function will travel along rows and compute the aggregate value for each column individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum the value for each column.\n",
    "\n",
    "df_1.sum(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum the value for each row.\n",
    "\n",
    "df_1.sum(axis='rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important aggregation function is `*.apply()`, which applies an arbitrary function to each row/column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.DataFrame([[1,1,1],[2,2,2],[3,3,3]])\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.apply(lambda x: sum(x**2), axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if you sum up columns that are NOT numerical values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = pd.DataFrame({\n",
    "    \"Age\": [10, 12, 12], \n",
    "    \"Name\": [\"Liz\", \"John\", \"Sam\"]})\n",
    "display(df_3)\n",
    "df_3.sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arithmetic\n",
    "We can also perform element-wise operations on dataframe columns or rows, e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4 = pd.DataFrame(\n",
    "    data=[[1,1,1],[2,2,2],[3,3,3]], \n",
    "    columns=[\"ColA\", \"ColB\", \"ColC\"], \n",
    "    index=[\"RowA\", \"RowB\", \"RowC\"])\n",
    "df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4[\"ColA\"] + df_4[\"ColB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas is smart enough to convert our list into a series and then add the two columns element-wise\n",
    "\n",
    "df_4[\"ColA\"] + [10, 11, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember, both rows AND columns can be represented as Pandas series\n",
    "\n",
    "df_4.loc[\"RowA\"] * df_4.loc[\"RowB\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas adheres to the same broadcasting rules as NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4[\"New\"] = df_4[\"ColB\"] ** 3\n",
    "df_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping\n",
    "A core functionality of Pandas is the ability to group data frames and apply functions to each individual group. The function `*.groupby(...)` defines groups based on common labels. Aggregators applied to this grouped data frame are then applied to each group individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"Height\": [178, 182, 158, 167, 177, 174, 175, 185], \n",
    "    \"Age\": [24, 33, 32, 18, 21, 28, 22, 29],\n",
    "    \"Gender\": [\"M\", \"M\", \"F\", \"F\", \"M\", \"F\", \"M\", \"F\"]})\n",
    "display(df)\n",
    "print(df.groupby(\"Gender\"))\n",
    "display(df.groupby(\"Gender\").mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also select columns without disturbing the grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping...\n",
    "\n",
    "print(df.groupby(\"Gender\")[\"Height\"])\n",
    "display(df.groupby(\"Gender\")[[\"Height\"]].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A useful function is `size()`, which counts how large each of the groups is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size is actually calculating the number of M and F\n",
    "\n",
    "df.groupby(\"Gender\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique and Duplicated Values\n",
    "Two functions can help us identify unique and duplicated values within Series objects. They are aptly names `unique()` and `duplicated()`, respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unique\n",
    "`*.unique()` returns only unique values of a **Series** object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### duplicated\n",
    "`*.duplicated()` identifies duplicated values in Series objects and returns a boolean Series. Entries that have already been seen are marked as `True` while new values are marked as `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When applied to Dataframes, `duplicated()` compares **ENTIRE ROWS** for duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([\n",
    "    [\"Dog\", 5], \n",
    "    [\"Cat\", 4], \n",
    "    [\"Dog\", 5], \n",
    "    [\"Fish\", 2], \n",
    "    [\"Cat\", 8]], \n",
    "    columns=[\"Animal\", \"Age\"])\n",
    "display(df)\n",
    "display(df.duplicated())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove duplicated rows from a data frame we could therefore do the following (just like in NumPy, booleans are negated with `~`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the unique values in a column\n",
    "\n",
    "df.Animal.unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Data Frames\n",
    "Pandas data frames can be treated like SQL tables and joined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.DataFrame({\n",
    "    \"Date\": pd.date_range(start=\"2018-10-01\", end=\"2018-10-07\"), \n",
    "    \"ItemID\": [\"A401\", \"C776\", \"A401\", \"FY554\", \"Y98R\", \"Y98R\", \"FY554\"]})\n",
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_info = pd.DataFrame({\n",
    "    \"ID\": [\"A401\", \"C776\", \"FY554\", \"Y98R\"],\n",
    "    \"Name\": [\"Toaster\", \"Vacuum Cleaner\", \"Washing Machine\", \"Clothes Iron\"], \n",
    "    \"Price\": [25, 220, 540, 85]})\n",
    "item_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.merge(right=item_info, how=\"inner\", left_on=\"ItemID\", right_on=\"ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge types:\n",
    "- **Inner**: keep only rows with corresponding IDs found in *both* data frames\n",
    "- **Left**: use only rows with IDs found in the left data frame\n",
    "- **Right**: use only rows with IDs found in the right data frame\n",
    "- **Outer**: use all keys that are in at least one of the data frames. This is essentially the combination of left and right joins\n",
    "\n",
    "Missing data will be replaced by `NaN` values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the three data frames so that we have all information available for Bob, Alice, Kevin, and Joshua in a single data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = pd.DataFrame(\n",
    "    data=[[\"Ting\", 5000], [\"Chong\", 4000], [\"David\", 8000]], \n",
    "    columns=[\"Name\", \"Salary\"])\n",
    "departments = pd.DataFrame(\n",
    "    data=[[\"Ting\", \"IT\"], [\"Evelyn\", \"Data Science\"], [\"Chong\", \"Data Science\"]], \n",
    "    columns=[\"Name\", \"Department\"])\n",
    "supervisors = pd.DataFrame(\n",
    "    data=[[\"IT\", \"Richard\"], [\"Data Science\", \"Darren\"], [\"Sales\", \"Yvonne\"]], \n",
    "    columns=[\"Department\", \"Supervisor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(salaries, departments, supervisors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here...\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
